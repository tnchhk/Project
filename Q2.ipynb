{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Question 2A\n",
    "\n",
    "##### When I accessed the site, and clicked in the women's handbag category, I picked up that every time I scroll down, it shows in the network console that I sent the below request:\n",
    "##### 'https://www.michaelkors.com/on/demandware.store/Sites-mk_us-Site/en_US/Search-UpdateGrid?cgid=womens-handbags&start=0&sz=24'\n",
    "##### here I identified that everytime i scroll down, value for 'sz' will increase. Hence I used this as a link for my request in the scraper. and to acquire all products at once, I started by changing the value for 'sz' to '500'\n",
    "##### 'https://www.michaelkors.com/on/demandware.store/Sites-mk_us-Site/en_US/Search-UpdateGrid?cgid=womens-handbags&start=0&sz=500'\n",
    "\n",
    "\n",
    "![alt text](image.png)\n",
    "\n",
    "##### the site would look like this\n",
    "![alt text](image-1.png)\n",
    "\n",
    "design diagram: \n",
    "![alt text](design_diagram.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import datetime\n",
    "import time\n",
    "import csv\n",
    "import schedule"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 1. Finding product tile wrapper\n",
    "![alt text](image-2.png)\n",
    "\n",
    "##### 2. Finding the product name\n",
    "![alt text](image-3.png)\n",
    "\n",
    "##### 3. Finding the price\n",
    "![alt text](image-4.png)\n",
    "\n",
    "##### 4. Finding a discounted price\n",
    "![alt text](image-5.png)\n",
    "\n",
    "##### 5. Finding the rating\n",
    "![alt text](image-6.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_michael_kors():\n",
    "\n",
    "    #since the request could not be executed without headers, I added the headers to the request\n",
    "    #The headers were copied from the network console when the inspect panel was opened \n",
    "    headers = {\n",
    "    \"accept\": \"text/html,application/xhtml+xml,application/xml;q=0.9,image/avif,image/webp,image/apng,/;q=0.8,application/signed-exchange;v=b3;q=0.7\",\n",
    "    \"accept-encoding\": \"gzip, deflate, br, zstd\",\n",
    "    \"accept-language\": \"en\",\n",
    "    \"cache-control\": \"max-age=0\",\n",
    "    \"priority\": \"u=0, i\",\n",
    "    \"sec-ch-ua\": \"\\\"Chromium\\\";v=\\\"130\\\", \\\"Google Chrome\\\";v=\\\"130\\\", \\\"Not?A_Brand\\\";v=\\\"99\\\"\",\n",
    "    \"sec-ch-ua-mobile\": \"?0\",\n",
    "    \"sec-ch-ua-platform\": \"Windows\",\n",
    "    \"sec-fetch-dest\": \"document\",\n",
    "    \"sec-fetch-mode\": \"navigate\",\n",
    "    \"sec-fetch-site\": \"none\",\n",
    "    \"sec-fetch-user\": \"?1\",\n",
    "    \"upgrade-insecure-requests\": \"1\",\n",
    "    \"user-agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/130.0.0.0 Safari/537.36\"\n",
    "    }\n",
    "    url = 'https://www.michaelkors.com/on/demandware.store/Sites-mk_us-Site/en_US/Search-UpdateGrid?cgid=womens-handbags&start=0&sz=500'\n",
    "    response = requests.get(url,headers=headers)\n",
    "\n",
    "\n",
    "    #send a request to the URL\n",
    "    soup = BeautifulSoup(response.content, 'html.parser')\n",
    "\n",
    "    #see markdown after this section for screenshots and description of how the relevant sections were identified in the html content\n",
    "\n",
    "    #parse the HTML content\n",
    "    products = soup.find_all('div', {'class': 'product-tile-wrapper'})\n",
    "\n",
    "    #Extract product name, price, discounted price ratings, timestamp\n",
    "    data = []\n",
    "    for product in products:\n",
    "        name = product.find('a', class_='link back-to-product-anchor-js').text.strip()\n",
    "\n",
    "    #For some products, there are original prices (if there is a separate discount). These may not appear in all products\n",
    "\n",
    "        price = \"\"  # Default value in case price is not found\n",
    "        list_span = product.find('span', {'class': 'list'})\n",
    "        if list_span:\n",
    "            value_span = list_span.find('span', {'class': 'value'})\n",
    "            if value_span:\n",
    "                price = value_span.text.strip()\n",
    "\n",
    "    #For most products, there is a sales price\n",
    "        sales_price = \"No sales price\"  # Default value in case price is not found\n",
    "\n",
    "        sales_span = product.find('span', {'class': 'sales'})\n",
    "        if sales_span:\n",
    "            value_span_1 = sales_span.find('span', {'class': 'value'})\n",
    "            if value_span_1:\n",
    "                sales_price = value_span_1.text.strip()    \n",
    "\n",
    "    #Not all products have ratings\n",
    "\n",
    "        ratings = \"\" \n",
    "\n",
    "        ratings_span = product.find('div', {'class': 'ratings'})\n",
    "        if ratings_span:\n",
    "            value_span_2 = ratings_span.find('span', {'class': 'sr-only'})\n",
    "            if value_span_2:\n",
    "                ratings = value_span_2.text.strip()\n",
    "\n",
    "\n",
    "        timestamp = datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S')\n",
    "        data.append([name, price, sales_price, ratings, timestamp])\n",
    "\n",
    "    #remove 'out of 5 Customer Rating' text from the ratings column\n",
    "    for row in data:\n",
    "        row[3] = row[3].replace(' out of 5 Customer Rating', '')\n",
    "\n",
    "    #add column headers\n",
    "    data.insert(0, ['Product Name', 'Original Price', 'Sales Price', 'Ratings', 'Timestamp'])\n",
    "\n",
    "    #Generate current date\n",
    "    current_date = datetime.datetime.now().strftime('%Y-%m-%d')\n",
    "    file_name = f'michael_kors_data_{current_date}.csv'\n",
    "\n",
    "    #write data to a CSV file\n",
    "    with open(file_name, mode='w', newline='') as file:\n",
    "        writer = csv.writer(file)\n",
    "        for row in data:\n",
    "            writer.writerow(row)\n",
    "\n",
    "#schedule the scraper to run at 9 am every day\n",
    "schedule.every().day.at(\"09:00\").do(scrape_michael_kors)\n",
    "\n",
    "while True:\n",
    "    schedule.run_pending()\n",
    "    time.sleep(1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 2b\n",
    "\n",
    "### Additional data points available in the html\n",
    "\n",
    "##### 1. Product tags such as \"Kors loves\" which outlines the shop's recommendations. Capturing these data provides an additional variable for analysis when understanding price, ratings of products\n",
    "![alt text](image-9.png)\n",
    "\n",
    "##### 2. Product subcategories such as colours \n",
    "![alt text](image-11.png)\n",
    "\n",
    "##### 3. images of products: Images, if made available, can be useful in downstream visualisation tools. Other technologies such as image recognition and computer vision can be applied. \n",
    "![alt text](image-12.png)\n",
    "\n",
    "##### 4. Product reviews: For each product there are reviews with different data points available for analysis. These data are available on the sites html - which will enable deeper analysis such as understanding how the product appeals to different customer segments, how the product stand out and compare against each other when measured by different features.\n",
    "\n",
    "###### 4.1 Review text data is available\n",
    "![alt text](image-14.png)\n",
    "\n",
    "###### 4.2 Customer data including gender and age\n",
    "![alt text](image-15.png)\n",
    "\n",
    "###### 4.3 Customer rating data across different features - such as quality, appearance\n",
    "![alt text](image-16.png)\n",
    "\n",
    "### Some data points that are not available on the html but potentially on the api end point\n",
    "\n",
    "##### 1. Inventory data: For example text that indicates number of items sold this week is an important data point indicating popularity of the item\n",
    "![alt text](image-10.png)\n",
    "\n",
    "##### 2. User data: data related to behaviour on the website such as how many clicks there are for each item, add-to-cart clicks, check out clicks, are also important data that will enable analysis on each individual product, and also the effectiveness of the check out process to customers\n",
    "\n",
    "##### 3. Customer data: Customers' order history, demographics, purchase frequency are data that help understanding how different product types appeal to different segments (across geographies, age) and lifecycle of a product (especially with purchase history and frequency data). These data are probably not available for scraping and would only be accessible through secured or authenticated API end points. \n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
